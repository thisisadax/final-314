{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dataset contains intracranial neural recordings from a patient undergoing surgery to treat severe epilepsy. These recordings were conducted while the patient was awake, lightly sedated, and deeply unconscious under the influence of an anesthetic called propofol. As neuroscientists, we are interested in how different parts of the brain communicate with each other during these three states, which we will refer to as WA (Wake), S (Sedated), and U (Unconscious).\n",
    "\n",
    "To measure communication between brain regions, we estimated correlations in neural activity between recordings made in each of these regions. We used this information to create what are called \"connectivity matrices\" for each arousal state. Think of a connectivity matrix as a symmetric table where each element describes how strongly two parts of the brain are communicating.\n",
    "\n",
    "Now, we want to see if the complexity of interregion communication throughout the brain changes when patients lose consciousness. To investigate this, we will use two mathematical tools: SVD (Singular Value Decomposition) and eigendecomposition. Both of these methods help us understand the structure of the connectivity matrices by breaking them down into components that can reveal global changes in network structure across arousal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the raw (unprocessed) connectivity matrices for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the mat file.\n",
    "states = ['WA', 'S', 'U']\n",
    "mat_contents = dict(np.load('raw_matrices.npz', allow_pickle=True))\n",
    "raw_matrices = {state: mat_contents[state] for state in states}\n",
    "\n",
    "# plot the raw connectivity matrices.\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12,4), constrained_layout=True)\n",
    "for i, state in enumerate(states):\n",
    "    cax = axes[i].imshow(raw_matrices[state], cmap='jet', interpolation='none')\n",
    "    axes[i].set_title(state, fontsize=20)\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "fig.colorbar(cax, ax=axes[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (1pt) Compute the eigenvalue spectrum for each state and plot them as lines on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the SVD for each transition matrix and plot the eigenvalues values.\n",
    "states = ['WA', 'S', 'U']\n",
    "mat_contents = dict(np.load('preprocessed_matrices.npz', allow_pickle=True))\n",
    "preprocessed_matrices = {state: mat_contents[state] for state in states}\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "for state in states:\n",
    "    matrix = preprocessed_matrices[state]\n",
    "    eigenvalues = ????? # compute the eigenvalues of the matrix.\n",
    "    plt.plot(eigenvalues, label=state) # plot the eigenvalues for the current state and give it a state label.\n",
    "\n",
    "# Add a legend, set the y-axis limits, and set the title.\n",
    "ax.legend()\n",
    "ax.set_ylim(-0.05,1)\n",
    "ax.set_xlim(0,75) \n",
    "ax.set_title('Eigenvalue spectrum', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (1pt) Compute the fraction of variance captured by a k-rank approximation of each preprocessed connectivity matrix with SVD and plot as a function of K for each arousal state. In general, which state is lower dimensional (i.e. requires fewer components to describe the same amount of variance)? Explain your reasoning.\n",
    "\n",
    "Here, to get the variance in the original data captured by a rank $k$ approximation, we can use the following equation, where $n$ is the total number of singular values and $S_i$ is the $i$-th singular value.\n",
    "$$\\text{Variance Explained}_k = \\frac{\\sum_{i=1}^{k} S_i^2}{\\sum_{j=1}^{n} S_j^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the fraction of variance captured by a k-rank approximation.\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "for state in states:\n",
    "    matrix = preprocessed_matrices[state]\n",
    "    s = ???? #compute the singular values of the matrix (don't forget to square them!!)\n",
    "    variances = s / s.sum()\n",
    "    plt.plot(np.cumsum(variances), label=state)\n",
    "plt.xlim(0,75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. (1pt) Effective dimensionality ($D_E$) is one way of measuring the intrinsic dimensionality of a given matrix. Implement a function that computes the effective dimensionality of the matrix and answer the following questions. Which state has the lowest effective dimensionality? Given what we know about the effective dimensionality of the connectivity matrices for each state, which would be best approximated by a low-rank approximation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$D_E=\\frac{(\\sum_{i=2}^{N}\\lambda_i)^2}{N*\\sum_{i=2}^{N}\\lambda_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the effective dimensionality of the input vector of eigenvalues.\n",
    "\n",
    "def effective_dimensionality(eigenvalues):\n",
    "    eigenvalues = ???? #1.  Exclude the first eigenvalue.\n",
    "    x1 = ????          #2.  Compute the numerator.\n",
    "    x2 = ????          #3.  Compute the denominator.\n",
    "    N =  ????          #4.  Compute N (the number of eigenvalues)\n",
    "    eff_dim = ????     #5.  Compute the effective dimensionality using the formula.\n",
    "    return eff_dim\n",
    "\n",
    "# Compute the effective dimensionality for each state.\n",
    "for state in states:\n",
    "    matrix = preprocessed_matrices[state]\n",
    "    eigenvalues = np.linalg.eigh(matrix)[0][::-1] # compute the eigenvalues of the matrix.\n",
    "    eff_dim = effective_dimensionality(eigenvalues)\n",
    "    print(f'state: {state}, effective dimensionality: {eff_dim:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
